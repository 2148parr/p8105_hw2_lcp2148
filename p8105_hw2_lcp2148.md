Homework 2
================
Lydia Parr
2019-10-09

## Setup

First, I am loading relevant packages.

``` r
library(tidyverse)
```

    ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──

    ## ✓ ggplot2 3.3.4     ✓ purrr   0.3.4
    ## ✓ tibble  3.1.2     ✓ dplyr   1.0.7
    ## ✓ tidyr   1.1.3     ✓ stringr 1.4.0
    ## ✓ readr   1.4.0     ✓ forcats 0.5.1

    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
library(dplyr)
```

## Problem 1

I placed the Mr. Trash Wheel data set into a subdirectory named
hw2\_data within this one, p8105\_hw2\_lcp2148. I renamed it
`trash_wheel.xlsx` for ease of use.

Next, I am reading in the Excel file and cleaning by:

-   specifying the sheet in the Excel file
-   omitting non-data entries (rows with notes / figures; columns
    containing notes)
-   omitting rows that do not include dumpster-specific data
-   converting variable names to snake case
-   rounding the number of sports balls to the nearest integer

``` r
mr_trash = read_excel("./hw2_data/trash_wheel.xlsx", sheet = "Mr. Trash Wheel", cellranger::cell_cols(1:14)) %>% drop_na() %>%
  janitor::clean_names() %>% 
   mutate(sports_balls = round(sports_balls))
```

Now I am reading and cleaning precipitation data for 2018 and 2019. I
will omit rows without precipitation data and add a variable for year
before combining the precipitation data sets and (trying to) convert
month to a character variable (it already is one, maybe that’s part of
why it didn’t work for me no matter what I tried).

``` r
precip2018 = read_excel("./hw2_data/trash_wheel.xlsx", sheet = "2018 Precipitation", skip = 1)
precip2018 = mutate(precip2018, 
       year = 2018) %>% janitor::clean_names()

precip2019 = read_excel("./hw2_data/trash_wheel.xlsx", sheet = "2019 Precipitation", skip = 1)
precip2019 = mutate(precip2019, 
       year = 2019) %>% janitor::clean_names()

precipboth = bind_rows(precip2018, precip2019) %>% drop_na()

dfmnth = tibble(
  month = 1:12, 
  mnth = c(month.name[month]))

precipfinal = left_join(precipboth, dfmnth, by = "month")
```

Key variables in Mr Trash Wheel include weight in tons, volume in cubic
years, homes powers, and number of trash items collected such as plastic
bottles, cigarette butts, and grocery bags (and of course, sports
balls). `summary(mr_trash)` The median weight was 3.380 tons, and the
mean was 9.037 tons. `print(mr_trash)` The number of observations in
this data set is 456. The median number of sports balls in a dumpster in
2019 `if (year == 2019){print median(pull(mr_trash, sports_balls))}`
\#\#use filter for this part

`summary(precipboth)` For the precipitation data set, the variables are
year, precipitation in inches, and months. Total precipitation in 2018
was `print median (pull(precip2018, x2))` 70.33 in.

## Problem 2

First I am importing pols-month.csv, unemployment.csv, and snp.csv.
tasks– month and year will be keys to merge data sets I cleaned the data
in pols-month.csv. Use separate() to break up the variable mon into
integer variables year, month, and day; replace month number with month
name; create a president variable taking values gop and dem, and remove
prez\_dem and prez\_gop; and remove the day variable.

Second, clean the data in snp.csv using a similar process to the above.
For consistency across datasets, arrange according to year and month,
and organize so that year and month are the leading columns.

Third, tidy the unemployment data so that it can be merged with the
previous datasets. This process will involve switching from “wide” to
“long” format; ensuring that key variables have the same name; and
ensuring that key variables take the same values.

Join the datasets by merging snp into pols, and merging unemployment
into the result.

Write a short paragraph about these datasets. Explain briefly what each
dataset contained, and describe the resulting dataset (e.g. give the
dimension, range of years, and names of key variables). \#\#
separate(mon, into = c(“year”, “month”, “day”)) %&gt;% \#\# mon, into =
c(“year”, “month”, “day”))

``` r
pols_month = read_csv(file = "./hw2_data/pols-month.csv") %>%
  janitor::clean_names() %>% 
  pivot_longer(
    cols = starts_with("prez_"),
    names_prefix = "prez_",
    names_to = "president")  %>%
  mutate(year = lubridate::year(mon), 
                month = lubridate::month(mon), 
                day = lubridate::day(mon)) %>% 
  left_join( dfmnth, by = "month")  %>% 
  select(-c(day, month))
```

    ## 
    ## ── Column specification ────────────────────────────────────────────────────────
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

``` r
unempl = read_csv(file = "./hw2_data/unemployment.csv") 
```

    ## 
    ## ── Column specification ────────────────────────────────────────────────────────
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

``` r
unempl = janitor::clean_names(unempl)

snp = read_csv(file = "./hw2_data/snp.csv")
```

    ## 
    ## ── Column specification ────────────────────────────────────────────────────────
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

``` r
snp = janitor::clean_names(snp)
```

## Problem 3

Next, I’m importing the baby names data. Task- data cleaning : names of
a categorical predictor and the case structure of string variables
changed over time; some rows seem duplicated, and these will need to be
removed (hint: google something like “dplyr remove duplicate rows” to
get started (do not understand what I’m seeing when I do this)).

Vaguely remember how to do these parts from lecture but will need to
re-watch again… Produce a well-structured, reader-friendly table showing
the rank in popularity of the name “Olivia” as a female baby name over
time; this should have rows for ethnicities and columns for year.
Produce a similar table showing the most popular name among male
children over time. Finally, for male, white non-hispanic children born
in 2016, produce a scatter plot showing the number of children with a
name (y axis) against the rank in popularity of that name (x axis).
filter(baby\_names, childs\_first\_name == “Olivia”)

``` r
baby_names = read_csv(file = "./hw2_data/Popular_Baby_Names.csv", 
  col_types = cols(
  `Year of Birth` = col_double(),
  Gender = col_character(),
  Ethnicity = col_character(),
  `Child's First Name` = col_character(),
  Count = col_double(),
  Rank = col_double()
  ))

baby_names = janitor::clean_names(baby_names)
```
